\section{Context and Motivations}
\label{sec:intro}
The success of Cloud Computing has driven the advent of Utility Computing.
However, Cloud Computing is a victim of its own success: In order to answer the
escalating demand for computing resources, Cloud Computing providers must
build data centers~(DCs) of ever-increasing size.

Besides facing the well-known
issues of large-scale platforms management, large-scale DCs have to deal with
energy considerations that limit the number of physical resources that one
location can host.

Instead of investigating alternative solutions that can tackle the aforementioned 
concerns, the current trend consists in deploying larger and larger DCs in few
strategic locations that deliver energy advantages.  For example, Western North
Carolina, USA, is an attractive area due to its abundant capacity of coal
and nuclear power following the departure of the textile and furniture
industry~\cite{greenpeace:2013}.  More recently, several proposals suggested building next
generation DCs close to the polar circle  in order to leverage free cooling
techniques, considering that cooling is accounting for a big part of the
consumed electricity \cite{greenberg:sigcomm09}. 


\subsection{Inherent Limitations of Large-scale DCs}

Although building large scale DCs  enables to cope with the actual demand,
% while continuing to operate UC resources through centralized software system 
it is far from delivering sustainable and efficient UC infrastructures.  In addition
to requiring the construction and the deployment of a complete network
infrastructure to reach each DC, it exacerbates the inherent limitations of the
Cloud Computing model:

\begin{itemize}
\item The externalization of private applications/data often faces legal issues
that restrain companies from outsourcing them on external infrastructures,
especially when located in other countries. 
\item The overhead implied by the unavoidable use of the Internet to reach
distant platforms is wasteful and costly in several situations: Deploying a
broadcasting service of local events or an online service to order pizzas at the
edge of the polar circle leads to important overheads since
most of the users may be located in the neighborhood of the
event/the pizzeria.  
\item The connectivity to the application/data cannot be ensured by centralized
dedicated centers, especially if they are located in a similar geographical
zone. The only way to ensure disaster recovery is to leverage distinct
sites.\footnote{``Amazon outages – lessons learned'',
\href{http://gigaom.com/cloud/amazon-outages-lessons-learned/}{http://gigaom.com/cloud/amazon-outages-lessons-learned/}
(valid on  Nov 2013, the 30\textsuperscript{th}).} 
\end{itemize}

The two first points could be partially tackled by hybrid or federated Cloud
solutions~\cite{armbrust:2010}, that aim at extending
the resources available on one Cloud with those of another one; however, the third 
one requires a disruptive change in
the way UC resources are managed.
%Deploying a local events broadcasting service or an
%online service to order pizza at the edge of the polar circle for instance, leads to an important overhead
%in terms of energy footprint, network exchanges as well as latency since it can be assumed
%that a vast majority of the users are located in the neighborhood of the event/the
%pizzeria.

Another issue is that, according to some projections of a recent IEEE
report~\cite{ieeenetreport:2012}, the network traffic continues to double roughly each
year. Bringing the IT services closer to the end-users is becoming crucial to limit
the energy impact of these exchanges and to save the bandwidth of some links. Similarly,
this notion of locality is also critical for the adoption of the UC model by applications
that need to deal with a large amount of data as getting them in and out actual UC
infrastructures may significantly impact the global performance~\cite{Fos11}. 

The concept of micro/nano DCs at the edge of the 
backbone~\cite{greenberg:sigcomm09} may be seen as a complementary solution to hybrid
platforms in order to reduce the overhead of network exchanges.  However, operating multiple small DCs breaks
the idea of resources mutualization for energy saving, making this approach questionable. 
%\ftodo[FQ$\rightarrow$AL]{Discovery ne va-t-il pas rencontrer le même problème ?}
% I gave an answer in the text explainging that network and cloud providers will mutualize their ressources
Moreover, 
the number of such micro/nano DCs will remain limited and the question of how
federating a large number of such facilities is still not solved.
\ftodo[FQ$\rightarrow$AL]{Enlever cette phrase ? Elle donne un a priori négatif sur les micro
DCs, alors qu'ils sont à la base de Discovery.. Faut que je cherche... Je tic aussi  mais bon j'aurais la response surement demain ! }


\subsection{Ubiquitous and Oversized Network Backbones}
While larger and larger DCs are created, people are (and will be more and more)
surrounded by computing resources, especially the ones in charge of
interconnecting all IT equipments. Even though these small and medium-size
facilities include resources that are barely used~\cite{Andrew:2003,
Benson:2010}, they can hardly be removed (\textit{e.g.} routers).  Considering
this important aspect, we claim that a new generation of UC platforms can be
delivered by deploying the concept of the  micro/nano DCs directly inside the
Internet backbone, starting from the core nodes of the backbone to the
different network access points in charge of interconnecting public and private
institutions.  By such a mean, network and UC providers would be enable to
mutualize resources that are mandatory to operate network/data centers while
delivering widely distributed UC platforms that can better match the
geographical dispersal of users. 

% TODO: AL -> ACO, please introduce this point latter in the chapter
% As a consequence, several initiatives started investigating how they could be
%better leveraged to support the requirements and constraints of current IT
%usages.  The concept of \emph{data furnaces} \cite{liu:hotcloud11} is one of
%the promising idea that seeks to mitigate the cost of operating
%network/computing resources by using them as a source of heat inside public
%buildings such as hospitals or universities. 

Figure \ref{fig:renater} illustrates the advantages of our proposal. It
 shows a snapshot of the network weather
map of RENATER\footnote{\href{http://www.renater.fr}{http://www.renater.fr}}, the network backbone dedicated to universities and research
institutions in France. It reveals several important points: 
\begin{itemize} 
\item As mentioned before, most of the resources are under-used (only two links are used between 45\% and 55\%, a few between 25\% and 40\% and the majority below the threshold of 25\%). 
\item The backbone was deployed and is renewed to match the demand: The density of
points of presence~(PoP) of the network as well as the bandwidth of each link are more important on the edge of large cities such as Paris, Lyon or
Marseille. 
\item The backbone was designed to avoid disconnections, since 95\% of the PoPs can be reached by at least two distinct routes.
\end{itemize}


\begin{figure}[b]
\includegraphics[width=12cm]{./FIGS/renater.png}
\vspace*{-.3cm}
\label{fig:renater}
\caption{The RENATER Weather Map on May 2013, the 27th, around 4PM.}
\centering {\small Available in real-time
at: \href{http://www.renater.fr/raccourci}{http://www.renater.fr/raccourci}}
\vspace*{-.3cm}
\end{figure}

\subsection{Locality-based Utility Computing}

%This chapter aims at introducing a new generation of UC platforms that can be
%seen somehow as an extension of the concept of micro DCs. The main change is to
%consider locality as a key point of UC services and to leverage facilities
%composing the internet backbone.  %Instead of building and deploying dedicated
%facilities, we claim that next UC
%infrastructures should be tightly coupled with any facilities available through
%the Internet, starting from the core routers of the backbone, the different
%network access points and any small and medium-size computing infrastructures
%that may be provisioned by public and private institutions. 

% Although it involves radical changes in the way
%physical and virtual resources are managed, locating and operating computing
%power and data on
%facilities close to the end-users will deliver highly efficient
%and sustainable UC services, resolving inherent limitations of the cloud computing model leveraging large-scale DCs. 

This chapter aims at introducing locality-based UC infrastructures, a new
generation of UC platforms that resolves the lack of locality of current
solutions relying on large-scale DCs. Although it involves radical changes in
the way physical and virtual resources are managed,  leveraging network centers
is a promising way to deliver highly efficient and sustainable UC services, 

From the physical point of view, network backbones such as the RENATER one provide
appropriate infrastructures, that is, reliable and efficient enough to operate UC
resources spread across the different PoPs. Ideally, UC resources would be able to
directly
take advantage of computation cycles available on network active devices, \textit{i.e.} the one
in charge of routing packets. However, leveraging network resources to make external
computations may lead to important security concerns. Hence, we propose to extend each
network center with a number of servers dedicated to host VMs. As we can expect that the
distribution between network traffics and UC demands would be proportional, larger network
centers will be completed by more UC resources than the smaller ones. Moreover by deploying
UC services on relevant PoPs, a LUC infrastructure will be able to natively confine
network exchanges to a minimal scope, minimizing both the energy footprint of the network
and the impact on latency.

From the software point of view, the main challenge is to design a complete distributed
system in charge of turning a complex and diverse network of resources into a collection
of abstracted computing facilities that is both reliable and easy to operate.

\begin{svgraybox}
By designing an advanced system that offers the possibility to operate a large
number of UC resources spread throughout distinct sites \ie, a \emph{LUC
  Operating System}, in a unified manner,
ISPs as well as academic and private institutions in
charge of operating a network backbone will be able to build an extreme-scale
LUC infrastructure with a limited additional cost. Instead of redeploying a
complete installation, they will be able to leverage IT resources and
specific devices such as computer room air conditioning units, inverters or
redundant power supplies already present on each center of their
backbone. 
\end{svgraybox}


\medskip
%This chapter  describes  how such a new
%generation of highly efficient and sustainable UC can emerge through an integrated
%system, \ie the \emph{LUC Operating System}, leveraging advanced and P2P system mechanisms.

In addition to consider \emph{Locality} as a primary concern, the novelty of the LUC OS
proposal is to consider VM as the basic object it manipulates.  Unlike existing
research on distributed operating systems that have been designed on the process concept, a LUC OS will manipulate VMs throughout a federation of widely distributed
physical machines. Virtualization technologies abstract out hardware heterogeneity, and allow
transparent deployment, preemption, and migration of virtualized
environments (VEs), \ie a set of interconnected VMs.
By dramatically increasing the flexibility of resource management, virtualization 
allows to leverage state-of-the-art results from other distributed
systems areas such as autonomous and decentralized systems.  
Our goal is to build a system that allows end-users to launch VEs over a
distributed infrastructure as simply as they launch processes on a
local machine, \ie  without the burden of dealing with resources
availability or location.

%\paragraph{Chapter Outline.} 
Section~\ref{sec:challenges} describes the key objectives of a LUC OS and the associated challenges. 
Section~\ref{sec:background} explains why our vision differs from actual and previous UC solutions. In
Section~\ref{sec:archi}, we present how such a unified system may be designed
by delivering the premises of the \discovery system, an agent-based system
enabling distributed and cooperative management of virtual environments over a
large-scale distributed infrastructure.
Future work as well as opportunities  are addressed in Section~\ref{sec:future}. Finally Section~\ref{sec:conclusion} concludes this chapter. 
