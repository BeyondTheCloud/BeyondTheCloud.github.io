\section{Introduction}
\label{sec:intro} 
% \AL{1./ le cloud centralisé c'est pas bien }
% \AL{2./ il faut mettre en place le concept de microDCs}
% \AL{3./ pour le mettre en oeuvre on propose tout simplement de s'appuyer sur les
% points de presence}
% \AL{4./ faire une fédération de pleins de petits OpenStack n'est pas la bonne 
% approche car si on perd les noeuds de service sur un micro DC, on a perdu tout 
% le micro DC en plus d'ajouter un cout, puisque sur chaque microDCs, il faut des 
% noeuds dediées à ces noeuds de services}
% \AL{5./ il faut un systeme qui va etre capable d'operer de maniere unifié une 
% telle infrastructure}



The success of Cloud Computing has driven the advent of Utility Computing (UC). 
However to answer the escalating demand for computing resources, 
Cloud Computing providers must build data centers (DCs) of ever-increasing size.
This concentration of computing ressources leads to issues like connectivity to
the application/data located in a similar geographical zone during disasters or
outages. Besides facing the well-known issues, large-scale DCs have now to deal 
with energy considerations that limit the number of physical resources that one 
location can host.

Cloud providers concentrate the production of computing resources in 
data-centers that contains tens of thousand of servers, enabling IaaS mechanisms
to take advantage of fast network with extremely low latency. However this ever 
increasing data-centers size has become a problem, as many data-centers require 
dedicated electrical and cooling infrastructure. As an alternative to 
concentrating the production of computing resources, we propose to study a model
where this production is deconcentrated.




With this model, the cloud operating system will have to reach high scalability 
criteria: managing thousands of servers used by hundreds of users. Popular peer 
to peer file sharing systems already work at this scale order: bittorrent 
clients enable hundreds of thousands of users to share millions of file spread 
over the internet, and if we disregard trackers, this protocol is totally 
decentralized with no single point of failure (SPOF). That is why we propose to 
learn from peer to peer file sharing experience, in order to build massively 
distributed clouds. However a recent IEEE report \cite{ieeenetreport:2012} shows
that network traffic continues to double roughly every year. Consequently, 
bringing computing resources closer to the end-users would minimize the energy
impact and save bandwidth. Leveraging the concept of micro data-centers 
proposed by \cite{greenberg:2008}, we suggest to build a cloud operating system 
that will be distributed over a set of geographically spread small data-centers. 



% All these problems can be tackled by hybrid or federated Cloud solutions 
% \cite{armbrust:2010}, that aim at extending the resources available on one Cloud
% with those of another one. 

The concept of micro/nano DCs at the edge of the backbone \cite{greenberg:2008} 
may be seen as a solution to reduce the network overhead. Hence, we propose to 
extend each points of presence (PoP) with a number of servers dedicated to 
virtual machines (VMs) hosting. From the physical point of view, network 
backbones provide appropriate infrastructures, i.e., reliable and efficient 
enough to operate UC resources spread across the different PoPs. Ideally, UC 
resources would be able to directly take advantage of computation cycles 
available on network active devices, i.e. those in charge of routing packets.


% Leveraging the concept of micro data-centers proposed by \cite{greenberg:2008},
% we suggest to build a cloud operating system that will run in a distributed
% manner over a set a small data-centers geographically spread. This cloud 
% operating system will have to reach high scalability criteria: managing 
% thousands of servers used by hundreds of users. Popular peer to peer file
% sharing systems already work at this scale order: bittorrent clients enable 
% hundreds of thousands of users to share millions of file spread over the 
% internet. If we disregard trackers, this protocol is totally decentralized with 
% no single point of failure (SPOF). That is why we propose to learn from peer to 
% peer file sharing experience, in order to build massively distributed clouds.

% All these problems can be tackled by hybrid or federated Cloud solutions 
% \cite{armbrust:2010}, that aim at extending the resources available on one Cloud
% with those of another one. However a recent IEEE report 
% \cite{ieeenetreport:2012} shows that network traffic continues to double 
% roughly every year. Consequently, bringing computing resources closer to the 
% end-users, thus minimizing the energy impact and saving bandwidth.

% The concept of micro/nano DCs at the edge of the backbone \cite{greenberg:2008} 
% may be seen as a solution to reduce the network overhead. Hence, we propose to 
% extend each points of presence (PoP) with a number of servers dedicated to 
% hosting virtual machines (VMs). From the physical point of view, network 
% backbones provide appropriate infrastructures, i.e., reliable and efficient 
% enough to operate UC resources spread across the different PoPs. Ideally, UC 
% resources would be able to directly take advantage of computation cycles 
% available on network active devices, i.e. those in charge of routing packets.





Proponents of Cloud federations would argue that is it possible to perform
a federation a micro-Clouds hosted on each micro DC, thus having a service node
in each micro-Cloud. However this solution is not without its flaw: aside from
wasting one node in each PoP, when a service node fails all the node generating
the computing power become unusable.

We propose the LUC Operating System (OS), an advanced system being able to unify
many UC resources distributed on distinct sites, that would enable Internet service 
providers (ISPs) and other institutions in charge of operating a network 
backbone to build an extreme-scale LUC infrastructure with a limited additional 
cost. Instead of redeploying a complete installation, they will be able to 
leverage IT resources and specific devices such as computer room air 
conditioning units, inverters or redundant power supplies already present in 
each center of their backbone.

The remainder of this article is structured as follows. In Section 2, we start 
from the reference architecture proposition \cite{moreno2012iaas} and we discuss
challenges to need to be solved for building massively distributed clouds. 
Section 3 gives an overview of the LUC OS design proposal that meet requirements
from Section 2. In Section 4, we describe existing mechanisms that we will 
revisit to build the LUC OS. Finally, we discuss perspectives and conclude this 
article in Section 5.
